# 1. 카프카 브로커, 클러스터, 주키퍼

## 카프카 브로커

- 카프카 클라이언트와 데이터를 주고받기 위해 사용하는 주체
- 데이터를 분산 저장하여 장애가 발생하더라도 안전하게 사용할 수 있도록 도와주는 애플리케이션
- 하나의 서버에는 한 개의 카프카 브로커 프로세스가 실행됨

- 카프카 클러스터로 묶인 브로커들은 프로듀서가 보낸 데이터를 안전하게 분산 저장하고 복제하는 역할을 수행

### 데이터 저장, 전송

- 프로듀서로부터 데이터를 전달받으면 카프카 브로커는 프로듀서가 요청한 토픽의 파티션에 데이터를 저장
- 컨슈머가 데이터를 요청하면 파팃녀에 저장된 데이터를 전달
- 프로듀서로부터 전달된 데이터는 파일 시스템에 저장됨



### 데이터 복제, 싱크

- 카프카의 데이터 복제는 파티션 단위로 이루어짐
- 복제된 파티션은 리더와 팔로워로 구성됨
    - 리더 : 프로듀서 또는 컨슈머와 직접 통신하는 파티션
    - 팔로워 : 나머지 복제 데이터를 가지고 있는 파티션
        - 팔로워 파티션들은 리더 파티션의 오프셋을 확인하여 현재 자신이 가지고 있는 오프셋과 차이가 나는 경우 리더 파티션으로부터 데이터를 가져와 자신의 파티션에 저장 -> 복제
- 복제를 통해 데이터를 안전하게 사용할 수 있는 강력한 장점이 있음 -> 2 이상의 복제 개수를 정하는 것이 중요



### 컨트롤러

- 클러스터의 다수 브로커 중 한 대가 컨트롤러의 역할을 함
- 컨트롤러는 다른 브로커들의 상태를 체크하고 브로커가 클러스터에서 빠지는 경우 해당 브로커에 존재하는 리더 파티션을 재분배



### 데이터 삭제

- 오직 브로커만이 데이터를 삭제할 수 있음
- 데이터 삭제는 파일 단위로 이루어지는데 이 단위를 로그 세그먼트라고 부름
    - 특정 데이터 선별 삭제 불가



### 컨슈머 오프셋 저장

- 컨슈머 그룹은 토픽이 특정 파티션으로부터 데이터를 가져가서 처리하고 이 파티션의 어느 레코드까지 가져갔는지 확인하기 위해 오프셋을 커밋함



## 주키퍼

- 카프카의 메타데이터를 관리하는 데에 사용함



# 2. 토픽과 파티션

- 토픽
    - 카프카에서 데이터를 구분하기 위해 사용하는 단위
    - 토픽은 1개 이상의 파티션을 소유하고 있음
- 파티션
    - 프로듀서가 보낸 데이터들이 들어가 저장되는데 이 데이터를 레코드라고 부름
    - 파티션은 그룹으로 묶인 컨슈머들이 레코드를 병렬로 처리할 수 있도록 매칭됨
    - 자료구조의 큐와 비스한 구조
        - 먼저 들어간 레코드는 컨슈머가 먼저 가져가게 됨
        - 삭제는 X



# 3. 레코드

- 타임스탬프
    - 프로듀서에서 해당 레코드가 생성된 시점의 유닉스 타임이 설정됨
- 메시지 키
    - 메시지 값을 순서대로 처리하거나 메시지 값의 종류를 나타내기 위해 사용함
    - 메시지 키를 사용하면 프로듀서가 토픽에 레코드를 전송할 떄 메시지 키의 해시값을 토대로 파티션을 지정하게 됨
- 메시지 값
    - 실질적으로 처리할 데이터가 들어 있음
    - 메시지 키와 메시지 값은 직렬화되어 브로커로 전송됨
    - 컨슈머가 이용할 때는 직렬화한 형태와 동일한 형태로 역직렬화를 수행해야 함



# 4. 카프카 클라이언트

## 1. 프로듀서 API

- 카프카에서 데이터의 시작점은 프로듀서
- 프로듀서 애플리케이션은 카프카에 필요한 데이터를 선언하고 브로커의 특정 토픽의 파티션에 전송함

```java
public class SimpleProducer {
    private final static Logger logger = LoggerFactory.getLogger(SimpleProducer.class);
    /**
     * 1. 프로듀서는 생성한 레코드를 전송하기 위해 전송하고자 하는 토픽을 알고 있어야 한다.
     * 토픽을 지정하지 않고서는 데이터를 전송할 수 없기 때문
     * 토픽 이름은 Producer Record 인스턴스를 생성할 때 사용됨
     * */
    private final static String TOPIC_NAME = "test";
    private final static String BOOTSTRAP_SERVERS = "my-kafka:9092"; // 전송하고자 하는 카프카 클러스터 서버의 host와 IP를 지정

    public static void main(String[] args) {
        /* *
         * 2. Properties에는 KafkaProducer 인스턴스를 생성하기 위한 프로듀서 옵션들을 key/value 값으로 선언함
         * 필수 옵션을 반드시 선언해야 하며, 선택 옵션은 선언하지 않아도 됨
         * */
        Properties configs = new Properties();
        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);

        /* *
         * 3. 메시지 키, 메시지 값을 직렬하기 위한 직렬화 클래스를 선언
         * String을 직렬화하기 위한 카프카 라이브러리의 StringSerializer 사용
         * */
        configs.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        configs.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

        /* *
         * 4. Properties를 KafkaProducer의 생성 파라미터로 추가하여 인스턴스를 생성
         *  producer 인스턴스는 ProducerRecord를 전송할 떄 사용
         * */
        KafkaProducer<String, String> producer = new KafkaProducer<>(configs);

        /* *
         * 5. 메시지 값 선언
         * * */
        String messageValue = "testMessage";
        /* *
         * 6. 카프카 브로커로 데이터를 보내기 위해 ProducerRecord를 생성
         * - 토픽 이름과 메시지 값만 선언함
         * - 메시지 키는 따로 선언하지 않았으므로 null로 설정되어 전송됨
         * - ProducerRecord를 생성할 떄 생성자에 2개의 제네릭 값이 들어가는데, 이 값은 메시지 키와 메시지 값의 타입을 뜻함
         * */
        ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, messageValue);

        /* *
        * 7. 생성한 ProducerRecord를 전송하기 위해 record를 파라미터로 가지는 send() 메서드 호출
        * 파라미터로 들어간 record를 프로듀서 내부에 가지고 있다가 배치 형태로 묶어서 브로커에 전송 -> 배치 전송
        * * */
        producer.send(record);
        logger.info("{}", record);

        // 8. flush()를 통해 프로듀서 내부 버퍼에 가지고 있던 레코드 배치를 브로커로 전송
        producer.flush();

        // 9. 애플리케이션을 종료하기 전에 close() 메서드를 호출하여 producer 인스턴스의 리소스를 안전하게 종료료
        producer.close();
    }
}

```



### 프로듀서 중요 개념

- 프로듀서는 카프카 브로커로 데이터를 전송할 때 내부적으로 파티셔너, 배치 생성 단계를 거침

- `ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, messageValue);`

    - 전송하고자 하는 데이터는 ProducerRecord 클래스를 통해 인스턴스를 생성했지만
    - 토픽과 메시지 값만 설정했음

    - 해당 인스턵스 생성시 추가 파라미터를 오버로딩하여 ProducerRecord의 내부 변수를 선언할 수도 있음

- `producer.send(record);`

    - KafkaProducer 인스턴스가 send 메서드를 호출하면 ProducerRecord는 파티셔너에서 토픽의 어느 파티션으로 전송될 것인지 정해짐
    - 버퍼로 쌓아놓고 발송
    - 버퍼로 쌓인 데이터는 배치로 묶어서 전송 -> 처리량 향상



### 프로듀서 주요 옵션

- 필수 옵션 : 사용자가 반드시 설정해야하는 옵션
    - bootstrap.servers
        - 프로듀서가 데이터를 전송할 대상 카프카 클러스터에 속한 브로커의 호스트 이름: 포트를 1개 이상 작성
        - 2개 이상 입력하자 (이슈 없도록)
    - key.serializer
        - 레코드의 메시지 키를 직렬화하는 클래스를 지정
    - value.serializer
        - 레코드의 메시지 값을 직렬화하는 클래스를 지정
- 선택 옵션 : 사용자의 설정을 필수로 받지않음
    - acks : 프로듀서가 전송한 데이터가 브로커들에 정상적으로 저장되었는지 전송 성공 여부를 확인하는 데에 사용하는 옵션
    - buffer.memory : 브로커로 전송할 데이터를 배치로 모으기 위해 설정할 버퍼 메모리양을 지정
    - retries: 프로듀서가 브로커로부터 에러를 받고 난 뒤 재전송을 시도하는 횟수를 지정
    - batch.size : 배치로 전송할 레코드 최대 용량을 지정
    - linger.ms : 배치를 전송하기 전까지 기다리는 최소 시간
    - partitioner.class : 레코드를 파티션에 전송할 때 적용하는 파티셔너 클래스를 지정



### 메시지 키를 가진 데이터를 전송하는 프로듀서

- 메시지 키가 포함된 레코드를 전송하고 싶다면 ProducerRecord 생성 시 파라미터에 추가하자

`ProducerRecord<String, String> record = new ProducerRecord<>("test", "Pangyo", "23");`



### 커스텀 파티셔너를 가지는 프로듀서

- 특정 데이터를 가지는 레코드를 특정 파티션으로 보내야 할 때
- Partitioner 인터페이스를 사용하여 사용자 정의 파티셔너를 생성하자

```java
public class CustomPartitioner implements Partitioner {

    // 리컨값 -> 주어진 레코드가 들어갈 파티션 번호
    @Override
    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
        // 메시지 키를 지정하지 앟ㄴ은 경우
        if (keyBytes == null) {
            throw new InvalidRecordException("Need message key");
        }
        
        // 메시지 키가 Pangyo일 경우 파티션 0번으로 지정되도록 0을 리턴
        if (((String)key).equals("Pangyo")) {
            return 0;
        }
        
        // 메시지 키가 Pangyo가 아닐 경우 해시값을 지정하여 특정 파티션에 매칭되도록 설정
        List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);
        int numPartitions = partitions.size();
        return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;
    }

    @Override
    public void close() {

    }

    @Override
    public void configure(Map<String, ?> configs) {

    }
}

```
